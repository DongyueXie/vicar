% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ash_wrap.R
\name{ash_ruv4}
\alias{ash_ruv4}
\title{Use control genes to estimate hidden confounders and variance
inflation parameter, then run ASH.}
\usage{
ash_ruv4(Y, X, ctl = NULL, k = NULL, cov_of_interest = ncol(X),
  likelihood = c("t", "normal"), ash_args = list(), limmashrink = TRUE,
  degrees_freedom = NULL, include_intercept = TRUE, gls = TRUE,
  fa_func = pca_naive, fa_args = list())
}
\arguments{
\item{Y}{A matrix of numerics. These are the response variables
where each column has its own variance. In a gene expression
study, the rows are the individuals and the columns are the
genes.}

\item{X}{A matrix of numerics. The covariates of interest.}

\item{ctl}{A vector of logicals of length \code{ncol(Y)}. If
position i is \code{TRUE} then position i is considered a
negative control.}

\item{k}{A non-negative integer.The number of unobserved
confounders. If not specified and the R package sva is
installed, then this function will estimate the number of
hidden confounders using the methods of Buja and Eyuboglu
(1992).}

\item{cov_of_interest}{A positive integer. The column number of the
covariate in X whose coefficients you are interested in. The
rest are considered nuiszance parameters and are regressed out
by OLS. \code{ash_ruv4} only works with one covariate of
interest right now.}

\item{likelihood}{Either \code{"normal"} or \code{"t"}. If
\code{likelihood = "t"}, then the user may provide the degrees
of freedom via \code{degrees_freedom}.}

\item{ash_args}{A list of arguments to pass to ash. See
\code{\link[ashr]{ash.workhorse}} for details.}

\item{limmashrink}{A logical. Should we apply hierarchical
shrinkage to the variances (\code{TRUE}) or not (\code{FALSE})?
If \code{degrees_freedom = NULL} and \code{limmashrink = TRUE}
and \code{likelihood = "t"}, then we'll also use the limma
returned degrees of freedom.}

\item{degrees_freedom}{if \code{likelihood = "t"}, then this is the
user-defined degrees of freedom for that distribution. If
\code{degrees_freedom} is \code{NULL} then the degrees of
freedom will be the sample size minus the number of covariates
minus \code{k}.}

\item{include_intercept}{A logical. If \code{TRUE}, then it will
check \code{X} to see if it has an intercept term. If not, then
it will add an intercept term. If \code{FALSE}, then \code{X}
will be unchanged.}

\item{gls}{A logical. Should we use generalized least squares
(\code{TRUE}) or ordinary least squares (\code{FALSE}) for
estimating the confounders? The OLS version is equivalent to
using RUV4 to estimate the confounders.}

\item{fa_func}{A factor analysis function. The function must have
as inputs a numeric matrix \code{Y} and a rank (numeric scalar)
\code{r}. It must output numeric matrices \code{alpha} and
\code{Z} and a numeric vector \code{sig_diag}. \code{alpha} is
the estimate of the coefficients of the unobserved confounders,
so it must be an \code{r} by \code{ncol(Y)} matrix. \code{Z}
must be an \code{r} by \code{nrow(Y)} matrix. \code{sig_diag}
is the estimate of the column-wise variances so it must be of
length \code{ncol(Y)}. The default is the function
\code{pca_naive} that just uses the first \code{r} singular
vectors as the estimate of \code{alpha}. The estimated
variances are just the column-wise mean square.}

\item{fa_args}{A list. Additional arguments you want to pass to
fa_func.}
}
\value{
Except for the list \code{ruv4}, the values returned are
    the exact same as in \code{\link[ashr]{ash.workhorse}}. See that
    function for more details. Elements in the \code{ruv} are the
    exact same as returned in \code{\link{vruv4}}.
}
\description{
This function will perform a variant of Removing Unwanted Variation
4-step (RUV4) (Gagnon-Bartsch et al, 2013) where the control genes
are used not only to estimate the hidden confounders, but to
estimate a variance inflation parameter. This variance inflation
step is akin to the "empirical null" approach of Efron
(2004). After this procedure, Adaptive SHrinkage (ASH) (Stephens,
2016) is performed on the coefficient estimates and the inflated
standard errors.
}
\details{
The model is \deqn{Y = XB + ZA + E,} where \eqn{Y} is a matrix of
responses (e.g. log-transformed gene expression levels), \eqn{X} is
a matrix of covariates, \eqn{B} is a matrix of coefficients,
\eqn{Z} is a matrix of unobserved confounders, \eqn{A} is a matrix
of unobserved coefficients of the unobserved confounders, and
\eqn{E} is the noise matrix where the elements are independent
Gaussian and each column shares a common variance. The rows of
\eqn{Y} are the observations (e.g. individuals) and the columns of
\eqn{Y} are the response variables (e.g. genes).

This model is fit using a two-step approach proposed in
Gagnon-Bartsch et al (2013) and described in Wang et al (2015),
modified to include estimating a variance inflation
parameter. Rather than use OLS in the second step of this two-step
procedure, we estimate the coefficients using Adaptive SHrinkage
(ASH) (Stephens, 2016). In the current implementation, only the
coefficients of one covariate can be estimated using ASH. The rest
are regressed out using OLS.
}
\author{
David Gerard
}
\references{
Gagnon-Bartsch, J., Laurent Jacob, and Terence
    P. Speed. "Removing unwanted variation from high dimensional
    data with negative controls."
    Berkeley: Department of Statistics. University of California
    (2013).

    Andreas Buja and Nermin
    Eyuboglu. "Remarks on parallel analysis." Multivariate behavior
    research, 27(4):509-540, 1992.

    Bradley Efron
    "Large-Scale Simultaneous Hypothesis Testing: The Choice of a Null
    Hypothesis",
    Journal of the American Statistical Association, 99:465,
    96-104, 2004.

    Stephens, Matthew. "False Discovery Rates: A New Deal." bioRxiv
    (2016): 038216.

    Wang, J., Zhao, Q., Hastie, T., & Owen, A. B
    "Confounder Adjustment in Multiple Hypotheses Testing."
    arXiv preprint arXiv:1508.04178 (2015).
}

