% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ruv4.R
\name{vicarius_ruv4}
\alias{vicarius_ruv4}
\title{Calibrated RUV4 where the control genes are used to estimate hidden
confounders and variance inflation parameter.}
\usage{
vicarius_ruv4(Y, X, ctl, k = NULL, cov_of_interest = ncol(X),
  likelihood = c("t", "normal"), limmashrink = FALSE,
  degrees_freedom = NULL, include_intercept = TRUE, gls = TRUE,
  fa_func = pca_naive, fa_args = list())
}
\arguments{
\item{Y}{A matrix of numerics. These are the response variables
where each column has its own variance. In a gene expression
study, the rows are the individuals and the columns are the
genes.}

\item{X}{A matrix of numerics. The covariates of interest.}

\item{ctl}{A vector of logicals of length \code{ncol(Y)}. If
position i is \code{TRUE} then position i is considered a
negative control. If \code{ctl = NULL} (the default) then ASH
will be run on the OLS estimates and corresponding standard
errors.}

\item{k}{A non-negative integer.The number of unobserved
confounders. If not specified and the R package sva is
installed, then this function will estimate the number of
hidden confounders using the methods of Buja and Eyuboglu
(1992).}

\item{cov_of_interest}{A vector of positive integers. The column
numbers of the covariates in X whose coefficients you want to
apply ASH to.}

\item{likelihood}{Either \code{"normal"} or \code{"t"}. If
\code{likelihood = "t"}, then the user may provide the degrees
of freedom via \code{degrees_freedom}.}

\item{limmashrink}{A logical. Should we apply hierarchical
shrinkage to the variances (\code{TRUE}) or not (\code{FALSE})?}

\item{degrees_freedom}{if \code{likelihood = "t"}, then this is the
user-defined degrees of freedom for that distribution. If
\code{degrees_freedom} is \code{NULL} then the degrees of
freedom will be the sample size minus the number of covariates
minus \code{k}.}

\item{include_intercept}{A logical. If \code{TRUE}, then it will
check \code{X} to see if it has an intercept term. If not, then
it will add an intercept term. If \code{FALSE}, then \code{X}
will be unchanged.}

\item{gls}{A logical. Should we use generalized least squares
(\code{TRUE}) or ordinary least squares (\code{FALSE}) for
estimating the confounders? The OLS version is equivalent to
using RUV4 to estimate the confounders.}

\item{fa_func}{A factor analysis function. The function must have
as inputs a numeric matrix \code{Y} and a rank (numeric scalar)
\code{r}. It must output a numeric matrix \code{alpha} and a
numeric vector \code{sig_diag}. \code{alpha} is the estimate of
the coefficients of the unobserved confounders, so it must be
an \code{r} by \code{ncol(Y)} matrix. \code{sig_diag} is the
estimate of the column-wise variances so it must be of length
\code{ncol(Y)}. The default is the function \code{pca_naive}
that just uses the first \code{r} singular vectors as the
estimate of \code{alpha}. The estimated variances are just the
column-wise mean square.}

\item{fa_args}{A list. Additional arguments you want to pass to
fa_func.}
}
\value{
A list whose elements are:

    \code{multiplier} A numeric. The estimated variance inflation parameter.

    \code{betahat_ols} A vector of numerics. The ordinary least
    squares estimates of the coefficients of the covariate of
    interest. This is when not including the estimated confounding
    variables.

    \code{sebetahat_ols} A vector of positive numerics. The
    pre-inflation standard errors of \code{ruv$betahat} (NOT
    \code{ruv$betahat_ols}).

    \code{betahat} A vector of numerics. The ordinary least squares
    estimates of the coefficients of the covariate of interest WHEN
    YOU ALSO INCLUDE THE ESTIMATES OF THE UNOBSERVED CONFOUNDERS.

    \code{sebetahat} A vector of positive numerics. This is equal
    to \code{sebethat_ols * sqrt(multiplier)}. This is the
    post-inflation adjusted standard errors for \code{ruv$betahat}.

    \code{tstats} A vector of numerics. The t-statistics for
    testing against the null hypothesis of the coefficient of the
    covariate of interest being zero. This is after estimating the
    variance inflation parameter but before the posthoc-inflation.

    \code{pvalues} A vector of numerics. The p-values of said test
    above.

    \code{alphahat} A matrix of numerics. The estimates of the
    coefficients of the hidden confounders.

    \code{sigma2} A vector of positive numerics. The estimates of
    the variances PRIOR to inflation.

    \code{sigma2_adjusted} A vector of positive numerics. The
    estimates of the variances AFTER to inflation. This is equal to
    \code{sigma2 * multiplier}.

    \code{mult_matrix} A matrix of numerics. Equal to
    \code{solve(Rsub \%*\% t(Rsub))}. One multiplies \code{sigma2} or
    \code{simga2_adjused} by the diagonal elements of
    \code{mult_matrix} to get the standard errors of
    \code{betahat}.

    \code{Rsub} A matrix of numerics numeric. This is the submatrix
    of the R in the QR decomposition of X that corresponds to the
    covariates of interest. May be removed in the future.

    \code{Z1} A matrix of numerics of length 1. This is the
    estimated confounders (after a rotation). Not useful on it is
    own and is mostly returned for debugging purposes. It may be
    removed in the future.
}
\description{
This function will perform a variant of Removing Unwanted Variation
4-step (RUV4) (Gagnon-Bartsch et al, 2013) where the control genes
are used not only to estimate the hidden confounders, but to
estimate a variance inflation parameter. This variance inflation
step is akin to the "empirical null" approach of Efron (2004).
}
\details{
The model is \deqn{Y = XB + ZA + E,} where \eqn{Y} is a matrix of
responses (e.g. log-transformed gene expression levels), \eqn{X} is
a matrix of covariates, \eqn{B} is a matrix of coefficients,
\eqn{Z} is a matrix of unobserved confounders, \eqn{A} is a matrix
of unobserved coefficients of the unobserved confounders, and
\eqn{E} is the noise matrix where the elements are independent
Gaussian and each column shares a common variance. The rows of
\eqn{Y} are the observations (e.g. individuals) and the columns of
\eqn{Y} are the response variables (e.g. genes).

This model is fit using a two-step approach proposed in
Gagnon-Bartsch et al (2013) and described in Wang et al (2015),
modified to include estimating a variance inflation parameter. In
the current implementation, only the coefficients of one covariate
can be estimated using ASH. The rest are regressed out using OLS.
}
\author{
David Gerard
}
\references{
Gagnon-Bartsch, J., Laurent Jacob, and Terence
    P. Speed. "Removing unwanted variation from high dimensional
    data with negative controls."
    Berkeley: Department of Statistics. University of California
    (2013).

    Andreas Buja and Nermin
    Eyuboglu. "Remarks on parallel analysis." Multivariate behavior
    research, 27(4):509-540, 1992.

    Bradley Efron
    "Large-Scale Simultaneous Hypothesis Testing: The Choice of a Null
    Hypothesis",
    Journal of the American Statistical Association, 99:465,
    96-104, 2004.

    Wang, J., Zhao, Q., Hastie, T., & Owen, A. B
    "Confounder Adjustment in Multiple Hypotheses Testing."
    arXiv preprint arXiv:1508.04178 (2015).
}

